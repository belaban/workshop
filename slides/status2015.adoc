
Status JGroups 2015
===================
:author: Bela Ban belaban@yahoo.com
:backend: deckjs
:deckjs_transition: fade
:navigation:
:deckjs_theme: web-2.0
:goto:
:menu:
:toc:
:status:


Agenda
------
* 3.6.2 - 3.6.7
* JGroups 4.0 and NIO.2
* JGroups workshops



JGroups 3.6.2
-------------


FORK
----
* Handling of asymmetric deployments
* If a fork stack or fork channel is not available on all nodes of `{A,B,C,D}`, a sync RPC to all 4 nodes will block
* Wildfly


Programmatic creation of a stack does not consider system props
---------------------------------------------------------------
* System props such as `-Djgroups.bind_addr` or `-Djgroups.external_addr` now work with a programmatic stack



JGroups 3.6.3
-------------


MERGE3 improvements
-------------------
* Subgroups were incorrect
* Reduced number of rounds to merge edge-case splits
* Edge cases captured with unit tests

FILE_PING
---------
* Added option to remove zombie files
* Useful for all cloud discovery protocols (subclasses)



JGroups 3.6.4
-------------
* SASL improvements, bug fixes

AZURE_PING
----------
* Moved into its own GitHub repo due to dependencies (Rado)

FD_SOCK / FD
------------
* Members are never unsuspected
* When a member Q is suspected by P, P periodically multicasts a `SUSPECT(Q)` until a new view (without Q) is installed
* This doesn't stop when Q is _unsuspected_
* OK in FD_ALL

Discovery
---------
* Added option to run each request in a separate thread
* Useful when using `TCP` as transport and the first couple of nodes (e.g. `A` - `C`) in
  `initial_hosts=A,B,C,D,E,F` are unresponsive or dead

Support IPv6 in AUTH
--------------------
* Fixed membership would not recognize port `7800` in `fe80:0:0:0:20c:29ff:fe4d:e0c4%0:7800`
** Address without port is `fe80`

FORK
----
* Call life cycle methods
* Methods `start()`, `stop()` and `destroy()` of protocols in the fork stack are not called.
* Needed to add some ref-counting to call them on `ForkChannel.connect()/disconnect()/close()`. Also: destroy all
  fork stacks and their protocols on `FORK.destroy()`.

RELAY2: messages are lost
-------------------------
* When TransferQueueBundler (or any other bundler) receives messages (at the same time) to destinations `X` and
`SiteUUID("name", X)`, then they get sent in the same bundle, which is incorrect: one of the destinations will drop
a message
** Cause: missing impl of `equals()` and `hashCode()` in `SiteUUID`

TCP: unneeded copy of single message
------------------------------------
* When receiving a single message (compared to a batch), there's an unneeded copy of the message in TCP

Probe: ping multiple clusters
-----------------------------
* `probe.sh -addr 224.0.75.75 -addr 228.5.5.5`
* `java org.jgroups.tests.Probe -addr ff0e::0:75:75 -addr 192.168.1.3`




JGroups 3.6.5
-------------


TCP_NIO2
--------
* New transport
* See below

FORK
----
* Support state transfer
* All fork channels will get their individual states when `JChannel.getState()` is called

LockService.tryLock()
---------------------
* Can hang forever
* Caused by an incorrect conversion from nanos to millis

Table: longs wrap around incorrectly
------------------------------------
* `Table` is a core class and is used by `NAKACK2` and `UNICAST3`
* `Long` wrap-around incorrect: messages are lost
* Very unlikely: adding 100 million messages/sec to a table would cause a wrap-around in 15 years
** Unless some smart-ass dude injects a seqno of `Long.MAX_VALUE-100`... :-)
* Fixed by replacing `if(seq1 < seq2) ...` and `if(seq2 >= seq1) ...` by `if(seq1 - seq2 < 0) ...`
  and `if(seq2 - seq1 >= 0) ...`
* Unit test is `TableTest.testSeqnoOverflow()`

OpenStack discovery protocol failure
------------------------------------
* `SWIFT_PING` failed with OpenStack "Kilo"
* Reason: OpenStack Identity API switched from using XML to JSON

S3_PING / FILE_PING improvements
--------------------------------
* When members are killed ungracefully

GossipRouter
------------
* Use NIO building blocks to rewrite
* TcpClient, NioClient, TcpServer, NioServer
* These classes are also used to implement `TCP_NIO2`




JGroups 3.6.6
-------------


TCP_NIO2: fixed 2 critical bugs
-------------------------------
* Non-blocking sending of message batches and reusing of the bundler's buffer caused message corruption
* Messages keep piling up because the selector doesn't have a registration for `OP_READ` / `OP_WRITE`
** Cause: `SelectionKey.interestOps(ops)` is not thread safe, therefore concurrent registrations / de-registrations
   could lead to dropped registrations




JGroups 3.6.7 (wip)
-------------------
* Not yet released

UDP
---
* Back to using a MulticastSocket (instead of a DatagramSocket) to send multicast messages
* Fixes ip_ttl issue on Windows (exception when using IPv6)
* Performance is the same
* No need to change routing table on MacOS anymore

SASL and merging
----------------
* Merging wasn't handled




JGroups workshops
-----------------
* 4 workshops: Berlin (16 people), Rome (15 people), NYC (22) and Mountain View (4)
* 20 paying customers (money used to partially fund F2Fs)
* 2 workshops in 2016 ?





TCP_NIO2
--------

What is it ?
------------
* A new _non-blocking_ TCP transport based on NIO.2
* Replaces `TCP_NIO` (deprecated a long time ago)
* The (medium term) goal is to replace `TCP` as well
* Brand new, don't use in production yet (wait for 2-3 minor releases)
** But please experiment, benchmark etc
** Perf with `UPerf` and `MPerf` slightly better than `TCP`, but slower running the Infinispan testsuite
   (still need to investigate)


Features
--------
* Never blocks on reads, writes, accepts or connects
** We've had quite a few problems with threads blocked in TCP writes in the past
* Dramatic reduction of threads required: from `(N-1)*2` -> `1`
** _One_ thread for _all_ peer nodes (`TCP`: 2 threads per peer node)
* Still requires `N-1` TCP connections (like `TCP`)


How ?
-----
* The only blocking call is `select()` -> called by the (*one*) thread in `TCP_NIO2`
* Accepts, connects and writes are handled directly by the selector thread, reads are passed to the transport's thread pool
* Built by using reusable classes `TcpServer`, `NioServer`, `TcpClient` and `NioClient`
** Goal: mix blocking/non-blocking clients and blocking/non-blocking servers
** Used to rewrite `GossipRouter` (now very scalable), `TCPGOSSIP` (`RouterStub`), `TUNNEL`




JGroups 4.0 and NIO.2
---------------------
* Problems ... problems ... problems !


Main advantages of NIO.2
------------------------
* _Non-blocking_ messaging (accept, connect, write, read)
** DONE: `TCP_NIO2`
* Zero-copy writes and reads
** *Problems* !!
* on-heap ByteBuffers / off-heap ByteBuffers
** *Problems* !!
* Datagram channels
** *Problems* !!


Problem #1: size of ByteBuffer
------------------------------
* *Overhead of 48 bytes (without payload !)*
```
[belasmac] /Users/bela$ jol-size.sh java.nio.ByteBuffer

Running 64-bit HotSpot VM.
Using compressed oop with 3-bit shift.
Using compressed klass with 3-bit shift.
Objects are 8 bytes aligned.

java.nio.ByteBuffer object internals:
 OFFSET  SIZE    TYPE DESCRIPTION                    VALUE
      0    12         (object header)                N/A
     12     4     int Buffer.mark                    N/A
     16     8    long Buffer.address                 N/A
     24     4     int Buffer.position                N/A
     28     4     int Buffer.limit                   N/A
     32     4     int Buffer.capacity                N/A
     36     4     int ByteBuffer.offset              N/A
     40     1 boolean ByteBuffer.isReadOnly          N/A
     41     1 boolean ByteBuffer.bigEndian           N/A
     42     1 boolean ByteBuffer.nativeByteOrder     N/A
     43     1         (alignment/padding gap)        N/A
     44     4  byte[] ByteBuffer.hb                  N/A
Instance size: 48 bytes (estimated, the sample instance is not available)
Space losses: 1 bytes internal + 0 bytes external = 1 bytes total
```

Problem #2: DirectByteBuffer
----------------------------
* *Overhead of 64 bytes*:
```
[belasmac] /Users/bela$ jol-size.sh java.nio.DirectByteBuffer

Running 64-bit HotSpot VM.
Using compressed oop with 3-bit shift.
Using compressed klass with 3-bit shift.
Objects are 8 bytes aligned.

java.nio.DirectByteBuffer object internals:
 OFFSET  SIZE           TYPE DESCRIPTION                    VALUE
      0    12                (object header)                N/A
     12     4            int Buffer.mark                    N/A
     16     8           long Buffer.address                 N/A
     24     4            int Buffer.position                N/A
     28     4            int Buffer.limit                   N/A
     32     4            int Buffer.capacity                N/A
     36     4            int ByteBuffer.offset              N/A
     40     1        boolean ByteBuffer.isReadOnly          N/A
     41     1        boolean ByteBuffer.bigEndian           N/A
     42     1        boolean ByteBuffer.nativeByteOrder     N/A
     43     1                (alignment/padding gap)        N/A
     44     4         byte[] ByteBuffer.hb                  N/A
     48     4 FileDescriptor MappedByteBuffer.fd            N/A
     52     4         Object DirectByteBuffer.att           N/A
     56     4        Cleaner DirectByteBuffer.cleaner       N/A
     60     4                (loss due to the next object alignment)
Instance size: 64 bytes (estimated, the sample instance is not available)
Space losses: 1 bytes internal + 4 bytes external = 5 bytes total

```


Current org.jgroups.Message
---------------------------

[source,java]
----
public class Message {
    protected int offset, length; // 4+4 bytes
    protected byte[] buf;         // 4 bytes for ref
}
----
* Total size for payload: 12 bytes excluding actual bytes


Possible design using ByteBuffers
---------------------------------

[source,java]
----
public class Message {
    protected JGroupsBuffer buf; // interface
}
----

[source,java]
----
public interface JGroupsBuffer {
    int getOffset();
    int getLength();
    byte[] getBuf();
    ByteBuffer getByteBuffer();
}
----

* Implementations:

[source,java]
----
public class Buffer implements JGroupsBuffer {
    private final byte[] buf;
    private final int offset;
    private final int length;
}
----

and

[source,java]
----
public class ByteBuf implements JGroupsBuffer {
    protected ByteBuffer buf;
}
----


Size of existing Message
------------------------
* *Existing Message: 40 bytes*:

```
 OFFSET  SIZE    TYPE DESCRIPTION                    VALUE
      0     4         (object header)                01 00 00 00 (00000001 00000000 00000000 00000000) (1)
      4     4         (object header)                00 00 00 00 (00000000 00000000 00000000 00000000) (0)
      8     4         (object header)                c2 e2 01 f8 (11000010 11100010 00000001 11111000) (-134094142)
     12     4     int Message.offset                 0
     16     4     int Message.length                 0
     20     2   short Message.flags                  0
     22     1    byte Message.transient_flags        0
     23     1         (alignment/padding gap)        N/A
     24     4 Address Message.dest_addr              null
     28     4 Address Message.src_addr               null
     32     4  byte[] Message.buf                    null
     36     4 Headers Message.headers                (object)
Instance size: 40 bytes (reported by Instrumentation API)
Space losses: 1 bytes internal + 0 bytes external = 1 bytes total
```

Size of new Message with Buffer
-------------------------------
* *New Message: 32 bytes*:
```
 OFFSET  SIZE          TYPE DESCRIPTION                    VALUE
      0     4               (object header)                01 00 00 00 (00000001 00000000 00000000 00000000) (1)
      4     4               (object header)                00 00 00 00 (00000000 00000000 00000000 00000000) (0)
      8     4               (object header)                c2 e2 01 f8 (11000010 11100010 00000001 11111000) (-134094142)
     12     2         short Message.flags                  0
     14     1          byte Message.transient_flags        0
     15     1               (alignment/padding gap)        N/A
     16     4       Address Message.dest_addr              null
     20     4       Address Message.src_addr               null
     24     4 JGroupsBuffer Message.buf                    null
     28     4       Headers Message.headers                (object)
Instance size: 32 bytes (reported by Instrumentation API)
Space losses: 1 bytes internal + 0 bytes external = 1 bytes total
```

* *Buffer: 24 bytes*
```
OFFSET  SIZE   TYPE DESCRIPTION                    VALUE
      0    12        (object header)                N/A
     12     4    int Buffer.offset                  N/A
     16     4    int Buffer.length                  N/A
     20     4 byte[] Buffer.buf                     N/A
Instance size: 24 bytes (estimated, the sample instance is not available)
```

* Total: *56 bytes (+ 16 bytes (40%) per message)*


Size of new Message with ByteBuf
--------------------------------
* New Message (see above): 32 bytes
* *`ByteBuf`: 16 bytes*
```
OFFSET  SIZE       TYPE DESCRIPTION                    VALUE
      0     4            (object header)                01 00 00 00 (00000001 00000000 00000000 00000000) (1)
      4     4            (object header)                00 00 00 00 (00000000 00000000 00000000 00000000) (0)
      8     4            (object header)                c2 e2 01 f8 (11000010 11100010 00000001 11111000) (-134094142)
     12     4 ByteBuffer ByteBuf.buf                    null
Instance size: 16 bytes (reported by Instrumentation API)
Space losses: 0 bytes internal + 0 bytes external = 0 bytes total
```

* *New message size with `HeapByteBuffer`: 32 + 16 + 48 = 96 bytes: +56 bytes (+140%)*
* *New message size with `DirectByteBuffer`: 32 + 16 + 64 = 112 bytes: +72 bytes (+180%)*

* This does not take into account that we probably need an array of ByteBuffers,
  for gathering writes and scattering reads... -> even bigger


DatagramChannels and NIO.2
--------------------------
* DatagramChannels have to be _connected_ for gathering writes and scattering reads to work
* `ch.connect(X)` means that `ch` can only send to dest `X` or receive from `X`, e.g. `232.5.5.5`
* This would work for sending of multicasts, but not for
** reception of mcast packets as the addresses are the senders' addresses (and these vary)
** sending and reception of unicast messages as each dest/sender address might be different
* David Lloyd created a BZ against openjdk (in 2008) to provide GWs/SRs for unconnected DatagramChannels (still open)
** https://bugs.openjdk.java.net/browse/JDK-6696470
** Hannes Sowa said this would be simple to implement...
* *Conclusion: we cannot do GW/SR with DatagramChannels -> no zero copy in UDP*


DatagramChannels and NIO.2 II
-----------------------------
* Scattering reads requires fixed-size buffers, or else it won't work
* If we read the metadata first (e.g. number, type (heap,direct) and size of following buffers), then allocate buffers
  and try to read the buffers next, this won\'t work -> the first read reads the *entire datagram* and then discards
  the unread bytes
** Unlike TCP where this works as the unread bytes are left in the channel
* *Conclusion: we cannot do scattering reads on DatagramChannel*
** On top of not being able to do scattering reads over _unconnected_ DatagramChannels


Direct buffers
--------------
* Off-heap buffers, managed by the application
* The myth is that they don\'t cause any copying on send
* That's wrong, as the kernel will still perform copying (both in TCP and UDP) [Hannes]
** TCP needs to keep buffers around until they're acked, and can therefore not immediately reuse them, so it copies
   the buffers to be on the safe side
** System calls `splice`/`vmsplice` could be used for zero-copy but this isn't done in openjdk
** Nobody knows if/whether/when this will be implemented
* However, copying is really fast in the Linux kernel (Hannes) and also in the JVM


Direct buffers and memory management
------------------------------------
* Direct buffers have to be released at some point
* E.g. when `STABLE` frees messages that have been received everywhere
* Complex memory management: who own memory and who calls `release()` ?
* De-fragmentation will probably need to create a copy on the receive path


Conclusion
----------
* Non-blocking is more important than zero-copying
** Non-blocking is almost done with `TCP_NIO2`. More changes are needed (e.g. RpcDispatcher)
   to become non-blocking end-to-end
* Going from a `byte[]` buffer to a `Buffer` interface and accompanying implementations for byte arrays and `ByteBuffers`
  requires huge changes, and increases the memory footprint of messages.
** Not even sure this will be faster !
* *More work required to become completely non-blocking*
* *Zero-copy will not be tackled for now*


Comment David on NIO.2
----------------------
  I think your analysis is pretty complete and accurate.  The Oracle JDK team has shown little interest in enhancing this area at all, so I wouldn't count on anything from them.
  [...] I think if you were going to look into NIO, then TCP should be your focus.  NIO.2 does not add much in this area, [...].
  I wouldn't be losing any sleep over not using NIO.2 in general though.




Shared memory transport
-----------------------
* Goal: use shared memory to send messages to members on the same host (bypassing TC/IP)
* `FileChannel.map()` maps shared memory to a file channel interface
* However, since `FileChannel` doesn't implement `SelectableChannel`, we cannot register it with a `Selector` -> no
  notifications when contents have changed
** Consumers don't know when data is ready to be read: possing approach?
* Using a ring buffer in shared memory where the read pointer could only advance when all members to which a message
  was sent have acked reception of the message
** Sounds complex, need to investigate more


Multiple transports
-------------------
* UDP, TCP and shared mem transports in the same stack
* Defaults, e.g. multicast messages use `UDP`, unicasts `TCP`
** Can be overriden per message, with message flags
* Investigation hasn't started yet




Near-term roadmap
-----------------
* Complete and release 3.6.7
** Testing and perftest investigation `TCP_NIO2`
* JGroups 4.0
** API changes
** Make it completely non-blocking (e.g. RpcDispatcher and lambdas)
* Multiple transports
* Investigate shared memory transport
* RDMA (JNI?)


