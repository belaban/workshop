
Admin
=====
:author: Bela Ban belaban@yahoo.com
:backend: deckjs
:deckjs_transition: fade
:navigation:
:deckjs_theme: web-2.0
:goto:
:menu:
:toc:
:status:


////
Tuning
------
* Let's take a (non exhaustive) look at things that can be tuned
* Ref: https://developer.jboss.org/wiki/PerfTuning
////


Multicast routing
-----------------
* When using `UDP`, IP multicasting is required
* On some systems, multicast route(s) need to be added to the routing table
** Otherwise, the default route will be used
*** Note that some systems don't consult the routing table for IP multicast routing, only for unicast routing
* MacOS example:
----
# Adds a multicast route for 224.0.0.1-231.255.255.254
sudo route add -net 224.0.0.0/5 127.0.0.1

# Adds a multicast route for 232.0.0.1-239.255.255.254
sudo route add -net 232.0.0.0/5 192.168.1.3
----
** When binding to `127.0.0.1`, `UDP.mcast_addr` should be set to a value between `224.0.0.1` and `231.255.255.254`
*** `224.0.0.1` - `224.0.0.255` not recommended, can get dropped by switches
** When binding to `192.168.1.3`, `mcast_addr` should be set to a value between `232.0.0.1` and `239.255.255.254`
* Alternative: use <UDP `receive_on_all_interfaces="true" ... />`



Switching from UDP to TCP
-------------------------
* Copy `udp.xml` -> `tcp.xml`
* Change `UDP` to `TCP`
* Remove `mcast_send_buf_size`, `mcast_recv_buf_size`, `ip_ttl`, `tos`, `mcast_port`
* Change `ucast_send_buf_size` -> `send_buf_size`
* Change `ucast_recv_buf_size` -> `recv_buf_size`
* Add `bind_port="7800"` (for example) to `TCP`
* Rename `PING` to `TCPPING`, remove all attributes
** Add `initial_hosts=A[7800],B[7800],C[7800]` to `TCPPING`
*** `A` is the `bind_addr` of host A, `B` of host B etc
*** I'm assuming here that `bind_port` is `7800` everywhere
* Run a few Draw instances with -props ./tcp.xml
* Verify that `bind_addr`, `bind_port` and `initial_hosts` are OK:
----
[mac] /Users/bela/workshop/bin$ ./probe.sh jmx=TCP.bind jmx=TCPPING.init

#1 (344 bytes):
TCP={bind_addr=/192.168.1.3, bind_port=7800}
cluster=draw
view=[A|1] (2) [A, B]
physical_addr=192.168.1.3:7800
local_addr=A [1253cca8-19e8-068a-b773-5e2d3771f507]
TCPPING={initial_hosts=[192.168.1.3:7800, 192.168.1.3:7801, 192.168.1.3:7802]}


#2 (344 bytes):
TCP={bind_addr=/192.168.1.3, bind_port=7800}
cluster=draw
view=[A|1] (2) [A, B]
physical_addr=192.168.1.3:7801
local_addr=B [d77986dd-681c-a7fd-f6b7-bd2800c8b2f9]
TCPPING={initial_hosts=[192.168.1.3:7800, 192.168.1.3:7801, 192.168.1.3:7802]}

[mac] /Users/bela/workshop/bin$
----




Buffers
-------
* _Right size_ buffers
** Too small: packet drops, too big: wasted resources
** Bandwidth-delay product only works for point-to-point (TCP)
*** In the worst case, we need to multiply this by the number of senders (oversimplification)
**** Max traffic we can receive is `min(current_senders * rate, link_bandwidth)`
* Transport buffers:
** `UDP`: `mcast_send_buf_size`, `mcast_recv_buf_size`, `ucast_send_buf_size`, `ucast_recv_buf_size`
*** Linux: these buffer cannot be bigger than `net.core.rmem_max` (recv) or `net.core.wmem_max` (send)
** `TCP`: `send_buf_size`, `recv_buf_size`
* NIC input buffers: `/sbin/ifconfig txqueuelen 5000` (Linux)


////
Flow control
------------
* Multicast flow control: `MFC`, unicast flow control: `UFC`
* `UFC` not needed when the transport is `TCP`
* The more credits (`max_credits`) a sender has, the more data it can send until it blocks
* A higher `min_threshold` value leads to quicker credit replenishments by the receivers back to the senders
* However: if `max_credits` and `min_threshold` are too large, then the purpose of flow control is defeated
** Receivers might still run out of memory as they're getting more messages than they can handle
* Suggestion: test with load that's slightly higher than expected load, watch memory use over time
////

////
Transport resources
-------------------
* Thread pool buffers (regular, OOB, incoming, timer), queues
* All 4 thread pool use j.u.c.ThreadPoolExecutor with its semantics
** Create min threads, then fill queue (if enabled), then create up to max threads, then reject
* Hands off the internal pool (used by JGroups only) !
* Timer pool should not be changed either, unless we expect a lot of timer tasks, or long running tasks
* This leaves us with the default and OOB pools
////

Transport: default thread pool
------------------------------
* For regular (sender-FIFO) and `OOB` messages
* (Conceptual) queues are created for each sender
* Only 1 thread processes a queue, delivering _1 message at a time_
* The other messages for the same sender consume threads only to add the messages to the queue, then the thread is
  put back into the pool
* Recommendations for peak (receiving messages from N senders concurrently):
** Set min-threads to 0
** Regular messages: set max-threads to N+2 (2 spare threads)
** `OOB` messages: max number of OOB messages expected to be received concurrently
*** This number can be high because we won't reach it unless we have many concurrent messages
**** The thread idle time will reduce the active thread size after a while if not all threads > min-threads are used


////
Ethernet flow control 802.3x
----------------------------
* Good for `UDP`, bad for `TCP`
* Enable: `/sbin/ethtool -A eth0 tx on rx on` (Linux)
* Enable in switch as well
* Ref: https://developer.jboss.org/wiki/PerfTuning


Interrupt coalescing
--------------------
* Collects multiple interrupts and handles them together
* Less 'context switching'
* Slightly worse latency
* Example: `/usr/sbin/ethtool -C eth0 rx-usecs 75`
////


Jumbo frames
------------
* Increases the size of a datagram packet's MTU, e.g. from 1500 to 8000
* If we send large messages, fewer datagrams need to be sent
** 60'000 byte message: 40 packets with mtu=1500, 8 with mtu=8000
** `UDP`: if 1 datagram packet of a message is lost, we need to retransmit all IP packets
*** Smaller chance of dropping 1 out of 8 packets than 1 out of 40
* Excellent for high throughput
* Needs to be enabled on all hosts and the switch(es)


UDP versus TCP
--------------
* `UDP` sends 1 multicast packet to the switch, which copies it to all ports with subscribers for the multicast group
** Cost to send a group message to all cluster members: 1
* `TCP` sends the message to each member separately
** Cost: N-1 (where N is the cluster size)
** If `N-1 * message size` is larger than the link's bandwidth, this is a bottleneck
* TCP generates more traffic for group messages
* UDP more scalable in large clusters



Message bundling / batching
---------------------------
* JGroups by default queues smaller messages on the sender until a size threshold has been exceeded, or no more
  messages are available
----
loop
    while(queue not full and more msgs available)
        queue next message
    send message batch
endloop
----
* Sends a single message immediately (low latency)
* Sends many messages in the time it takes to add them to the queue and exceed the size threshold
* Queued messages are then sent as one big message
* Advantage: payload-to-header ratio is better, less overhead per message
* Batching can be bypassed by marking a message as `DONT_BUNDLE` and `OOB`
** Only recommended for selected (few) messages


Retransmission intervals in NAKACK2 and UNICAST3
------------------------------------------------
* Attribute `xmit_interval` defines the interval at which we're checking for missing messages and ask the sender
  for retransmission (NAKACK2,UNICAST3), or resend messages for which we haven't yet received an ack (UNICAST3)
* A small interval might lead to multiple redundant retransmission requests/responses
** This increases traffic and might compound the problem -> even more dropped packets due to buffer overflow
* If the interval is too high, retransmission may not be able to retransmit all missing messages (see next topic) in one go


////
Maximum size of retransmission requests
---------------------------------------
* In `NAKACK2` and `UNICAST3`, if too many messages are missing, a retransmit request message may become too big
* Only applicable to `UDP`
* Both protocols therefore only request for retransmission of the oldest N messages, such that the size of the retransmit
  request doesn't exceed the max datagram packet size
* The max size of a retransmit request can be configured: `max_xmit_req_size`
////


STABLE
------
* Purges messages seen by everyone in `NAKACK2`
* Low stable interval -> quick purging but more traffic
* High stable interval -> less traffic but memory accumulation
* Find the optimal tradeoff based on traffic pattern
* STABLE rounds can also be triggered manually / programmatically (`STABLE.gc()`)



Link bundling
--------------
* Logical network interface, but consisting of multiple physical NICs
* Each physical NIC might use a different network -> multiplies bandwidth
* Example: IP bonding (Linux)




Top JGroups problems
--------------------
* From
** Mailing lists
** Support cases
** Consulting
** Interaction with customers
** Bug reports





Problem #12: AWS
----------------
* Large packets sizes in EC2 are dropped
** The problem was that large packets using the default stack configuration for `FRAG2` (60k) were sometimes being dropped
   between some hosts.
** The cluster would work fine until a large amount of data was sent between some pairs of servers.
** Amazon support: this is an update for case 85983221. We are currently limited to packet sizes of 32k and below on Amazon
   EC2 and can confirm the issues you are facing for larger packet sizes. We are investigating a solution
   to this limitation. Please let us know if you can keep your packet sizes below this level, or if this
   is severe problem blocking your ability to operate.
* Solution: use `FRAG2` sizes of <= 32k if you are running in `UDP` mode under EC2.


Problem #10: `receive()` and `viewAccepted()` callbacks
------------------------------------------------------
* Invoking blocking RPCs or doing something long or blocking in these callbacks
* Because JGroups calls these callbacks on a thread from the incoming thread pool, all messages behind this one are stuck
  until the callback returns
* Solution: use a separate thread is some callback code needs to block, invoke a blocking RPC, or perform a long task


Problem #9: reusing a message (the Sebastian problem)
------------------------------------------------------
[source,java]
----
Message msg=new Message(null, "hello");
for(int i=0; i < 10; i++)
   channel.send(msg)
----
* Spot the problem ?



Problem #8: JGroups eating memory: NAKACK2 / STABLE
---------------------------------------------------
* Memory grows in `NAKACK`
* In most cases, this is caused by a slow member which hasn't yet been suspected and excluded (hinders progress)
* Symptom: one or more slow members prevent an agreement between all members on which messages have been seen and can
  be discarded -> memory accumulates
* Solution: remove / fix the slow or unresponsive members or decrease the failure detection timeout to exclude the member




Problem #7: seeing traffic from different clusters
--------------------------------------------------
* When using UDP, we get warnings that traffic from a different cluster was discarded
* This is caused by using the same `mcast_addr` and `mcast_port` in `UDP` in different clusters
* Solution: use different values for either or both attributes in `UDP` for each separate cluster




Problem #6: TCPPING
-------------------
* TCPPING.initial_hosts doesn't list all cluster members
** If `initial_hosts=A` and we have `{A,B,C}`, then `A` leaves, no new members can join
** Solutions:
*** List all members
*** Use `send_cache_on_join` (`3.6.1` and higher)
*** use `MPING` (if IP multicasting is enabled)

* TCPPING not merging
** Same as above: if we have `initial_hosts=A`, but 2 partitions `{A,B,C}` and `{X,Y,Z}`, then `X` will be able to send a
  message to `A`, but `A` won't be able to respond (it doesn't have `X`'s address) -> no merge


* TCPPING.initial_hosts lists the wrong members
** All members need to be listed with the `bind_addr` they're bound to and the `bind_port` they use

* TCPPING is used but TCP doesn't set `bind_port`
** If `TCP.bind_port` is 0, a random port will be used and we cannot list it in `TCPPING.initial_hosts`



Problem #5: IPv6
----------------
* Running in IPv6 without a correctly configured IPv6 routing table
** By default, the JVM uses IPv6, but the routing table is not configured correctly, or the config uses IPv4
** Solution: look at IPv6 routing or force use of IPv4 (`-Djava.net.preferIPv4Stack=true`)

* Mixing IPv4 and IPv6
** This works with TCP as IPv4 addresses are mapped to IPv4-mapped IPv6 addresses, but this is (IMO) hard to set up correctly

* Wiki: https://developer.jboss.org/wiki/IPv6



Problem #4: JGroups versions
----------------------------
* An old JGroups version is used
** Symptom: a bug that was fixed a long time ago pops up
** Side effect: Bela gets very tired having to waste time on some bug that's already been fixed
** Solution: upgrade to the latest stable JGroups version

* Different JGroups version in the same cluster
** Running different JGroups versions on different nodes might lead to subtle issues, e.g. dropping messages due to
   deserialization issues.
** Solution: run the same version on all cluster nodes

* Old JGroups configuration
** Sometimes, people upgrade to a newer JGroups version, but forget to upgrade their config(s) as well.
** Solution: always use the config template from the JGroups version you upgrade to and apply your specific changes



Problem #3: tinkering with configuration
----------------------------------------
* (The "I'm smarter than Bela" problem)

* Custom configuration files
** A configuration should never be built from the ground up; instead, copy `udp.xml` or `tcp.xml` from the JGroups JAR
   and modify it

* Removing \'unneeded' protocols
** Removing `UNICAST` because the transport is `TCP` (reliable): this won't work as `UNICAST` also performs ordering
** Symptoms: unicast messages can be unordered
** Removing `STABLE` causes OOMEs

* Putting protocols in the wrong place
** A configuration needs to be defined in a certain order; placing protocols in the wrong place almost always
   causes subtle issues



Problem #2: cluster falls apart
-------------------------------
* Low timeout in `FD` / `FD_ALL`
** GC, high network traffic or exhausted thread pools on the receivers can lead to missing heartbeats, causing members
   to be suspected.
** Symptoms: some members are suspected, excluded and later merged back
** Solution: use high timeouts in heartbeat based failure detection protocols and add `FD_SOCK` / `FD_HOST`

* IGMP Snooping
** Snooping (in the switch) listens on ports for IGMP joins and copies multicast packets for a groups to all joiners of
   that group.
** Buggy firmware code leads to that information getting dropped and multicast packets getting dropped until the
   information has been refreshed.
** Symptoms: multicast groups falls apart every N minutes
** Solution: upgrade switch firmware

* Faulty network card
** Sometimes a faulty NIC randomly drops packets, or drops sent packets but accepts received packets



Problem #1: members don't find each other
-----------------------------------------
* Binding to the loopback interface
** Setting `bind_addr` (in the transport) or system property `jgroups.bind_addr`
   to `127.0.0.1` works when members are running on the same host, but doesn't work across hosts

* Binding to the wrong network interface
** Binding to a VPN tunnel that's down, or `A` binding to `eth0` and `B` binding to `eth1` (different networks)

* Firewalls dropping packets
** Disable the firewall, to see if this helps (e.g. `sudo iptables -F` on Linux).
** If this is the issue, open ports for JGroups (`UDP.bind_port`, `FD_SOCK`, `STATE_SOCK`) and re-enable the firewall

* SELinux
** Restrictive vs. permissive

* Switch dropping packets
** Especially between VLANs. Check the switch configuration

* UDP: time-to-live loo low
** If `UDP` is used, increase the value of `ip_ttl`. See whether packets are received with wireshark / tcpdump




Logging
-------
* JGroups has no runtime dependencies on any logging framework (j.u.l. is used by default)
* At startup, JGroups looks for log4j2, j.u.l. (in this order)
** To force use of JDK logging, even if the log4j2 JARs are present, `-Djgroups.use.jdk_logger=true` can be used
* Custom loggers can be used instead of the ones supported by default. To do this, interface
`CustomLogFactory` has to be implemented:

[source,java]
----
public interface CustomLogFactory {
    Log getLog(Class clazz);
    Log getLog(String category);
}
----

* The implementation needs to return an implementation of `org.jgroups.logging.Log`.
* To force using the custom log implementation, the fully qualified classname of the custom log
  factory has to be provided with `-Djgroups.logging.log_factory_class=com.foo.MyCustomLogger`.
* Ref: http://www.jgroups.org/manual/index.html#Logging


JMX
---
* JGroups exposes attributes and operations of the channel and all protocols via JMX
* Has to be enabled with `-Dcom.sun.management.jmxremote` (or others, ie. remote JMX host:port etc)
* To expose a channel and its attributes via JMX:

[source,java]
----
public static void registerChannel(JChannel channel,String name) {
    JmxConfigurator.registerChannel(channel,
                                    Util.getMBeanServer(),
                                    (name != null? name : "jgroups"),
                                    channel.getClusterName(),
                                    true);
}

// Util.registerChannel((JChannel)channel, channel.getClusterName());

public static void unregisterChannel(Channe channel) {
    JmxConfigurator.unregisterChannel((JChannel)channel,
                                      Util.getMBeanServer(),
                                      channel.getClusterName(());
}
----
* Let's try this out with our ChatDemo




JGroups and Docker
------------------
* https://github.com/belaban/jgroups-docker





probe.sh
--------
* Probe is a simple program which sends IP multicasts to a given multicast group and port and prints all responses
* Functionality
** Read attributes
** Write attributes
** Invoke operations
** Insert new protocols, remove protocols
* Any application can implement a `ProbeHandler` and expose its attributes and operations
* Probe requests are simple strings that are parsed by cluster nodes
* Probe responses are strings, too
* To enable:

[source,xml]
----
<UDP enable_diagnostics="true"
     diagnostics_addr="xxx"
     diagnostics_port="xxx"
     ...
/>
----
* Let's run ChatDemo and explore the features of probe


Listing all cluster nodes
-------------------------

----
[mac] /Users/bela/workshop/bin$ ./probe.sh

-- sending probe on /224.0.75.75:7500

#1 (149 bytes):
local_addr=A [f91dce0b-a753-987d-9d18-a8e8d86950ee]
cluster=ChatCluster
view=[A|1] (2) [A, B]
physical_addr=127.0.0.1:52181
version=3.6.0.Final

#2 (149 bytes):
local_addr=B [9e413b1d-d2f7-eaac-cb67-8eb94b2ba352]
cluster=ChatCluster
view=[A|1] (2) [A, B]
physical_addr=127.0.0.1:58998
version=3.6.0.Final


2 responses (2 matches, 0 non matches)
[mac] /Users/bela/workshop/bin$
----


Reading attributes from a protocol
----------------------------------
* Reading the number of sent and received messages and bytes in `UDP`:

----
[mac] /Users/bela/workshop/bin$ ./probe.sh jmx=UDP.num_msgs,num_byt

#1 (246 bytes):
local_addr=A [f91dce0b-a753-987d-9d18-a8e8d86950ee]
cluster=ChatCluster
view=[A|1] (2) [A, B]
physical_addr=127.0.0.1:52181
jmx=UDP={num_msgs_received=36, num_msgs_sent=37, num_bytes_received=2325, num_bytes_sent=2470}

version=3.6.0.Final


#2 (246 bytes):
local_addr=B [9e413b1d-d2f7-eaac-cb67-8eb94b2ba352]
cluster=ChatCluster
view=[A|1] (2) [A, B]
physical_addr=127.0.0.1:58998
jmx=UDP={num_msgs_received=36, num_msgs_sent=36, num_bytes_received=2372, num_bytes_sent=2325}

version=3.6.0.Final

2 responses (2 matches, 0 non matches)
[mac] /Users/bela/workshop/bin$
----



Setting attributes
------------------
* Changing the log level of `NAKACK2` to `TRACE`:
----
./probe.sh jmx=NAKACK2.level=trace
----
* This allows an admin to change the log level temporarily, and reset it back to `WARN` later



Invoking an operation
---------------------
* Dump the retransmit tables in `NAKACK2`:

----
[mac] /Users/bela/workshop/bin$ ./probe.sh op=NAKACK2.printMessages

#1 (254 bytes):
local_addr=A [f91dce0b-a753-987d-9d18-a8e8d86950ee]
cluster=ChatCluster
view=[A|1] (2) [A, B]
physical_addr=127.0.0.1:52181
NAKACK2.printMessages=A:
B: [0 | 0 | 0] (0 elements, 0 missing)
A: [2 | 9 | 9] (0 elements, 0 missing)

#2 (254 bytes):
local_addr=B [9e413b1d-d2f7-eaac-cb67-8eb94b2ba352]
cluster=ChatCluster
view=[A|1] (2) [A, B]
physical_addr=127.0.0.1:58998
NAKACK2.printMessages=B:
B: [0 | 0 | 0] (0 elements, 0 missing)
A: [9 | 9 | 9] (0 elements, 0 missing)

[mac] /Users/bela/workshop/bin$
----


Printing the protocol stacks
----------------------------

----
[mac] /Users/bela/workshop/bin$ ./probe.sh print-protocols

#1 (140 bytes):
protocols=UDP
PING
MERGE3
FD_SOCK
FD_ALL
NAKACK2
UNICAST3
STABLE
GMS
UFC
MFC
FRAG2

#2 (140 bytes):
protocols=UDP
PING
MERGE3
FD_SOCK
FD_ALL
NAKACK2
UNICAST3
STABLE
GMS
UFC
MFC
FRAG2

[mac] /Users/bela/workshop/bin$
----


Inserting a protocol at runtime
-------------------------------
* Insert `PRINT_BYTES` above `UDP`:
----
./probe.sh insert-protocol=org.lab.protocols.PRINT_BYTES=above=UDP
----
* Remove `PRINT_BYTES`:
----
./probe.sh remove-protocol=PRINT_BYTES
----
* Works only for stateless protocols
* Use cases
** Temporary TRACE logging to see what's going on in a defective system, then disable TRACE again
** Insert a protocol that extracts relevant information about a cluster, stores this to a file and sends the file to
   support


Getting RPC stats
-----------------
* Use `probe.sh rpcs-enable-details` to turn on and `probe.sh rpcs-disable-details` to turn off
* `probe.sh rpcs rpcs-details` dumps stats on RPCs, e.g.
----
#1 (481 bytes):
local_addr=C [ip=127.0.0.1:55535, version=3.6.8-SNAPSHOT, cluster=uperf, 4 mbr(s)]
uperf: sync  multicast RPCs=0
uperf: async unicast   RPCs=0
uperf: async multicast RPCs=0
uperf: sync  anycast   RPCs=67480
uperf: async anycast   RPCs=0
uperf: sync  unicast   RPCs=189064
rpcs-details=
D: async: 0, sync: 130434, min/max/avg (ms): 0.13/924.88/2.613
A: async: 0, sync: 130243, min/max/avg (ms): 0.11/926.35/2.541
B: async: 0, sync: 63346, min/max/avg (ms): 0.14/73.94/2.221

#2 (547 bytes):
local_addr=A [ip=127.0.0.1:65387, version=3.6.8-SNAPSHOT, cluster=uperf, 4 mbr(s)]
uperf: sync  multicast RPCs=5
uperf: async unicast   RPCs=0
uperf: async multicast RPCs=0
uperf: sync  anycast   RPCs=67528
uperf: async anycast   RPCs=0
uperf: sync  unicast   RPCs=189200
rpcs-details=
<all>: async: 0, sync: 5, min/max/avg (ms): 2.11/9255.10/4917.072
C: async: 0, sync: 130387, min/max/avg (ms): 0.13/929.71/2.467
D: async: 0, sync: 63340, min/max/avg (ms): 0.13/63.74/2.469
B: async: 0, sync: 130529, min/max/avg (ms): 0.13/929.71/2.328
----


Use of probe when IP multicasting is not available
--------------------------------------------------
* `probe.sh -addr <address of any member> <diagnostics port (default: 7500)>`
** This asks any member for the addresses of _all members_ and then sends the probe request to all members in turn
* Note that any member can also be queried via simple datagram packets, e.g.:
----
[mac] /Users/bela/workshop/bin$ nc -u 192.168.1.3 7500
uuids
local_addr=A
uuids=2 elements:
B: ca335dc2-f30f-6e11-d13a-b029e3e9e2f1: 192.168.1.3:7801 (300 secs old)
A: 9dd407ae-577d-68b1-4f1e-6623279bb6ed: 192.168.1.3:7800 (31 secs old)

local_addr=A [9dd407ae-577d-68b1-4f1e-6623279bb6ed]
cluster=draw
view=[A|1] (2) [A, B]
physical_addr=192.168.1.3:7800
version=3.6.1.Final
^C
[mac] /Users/bela/workshop/bin$
----


Running the performance test
----------------------------
* We'll run just one test: `UPerf`
* This mimics the way Infinispan works and uses mostly unicast messages
* Every node starts 100 threads which mimic doing 20% puts and 80% gets (sync RPCs) on a distributed cache
* This will be used in the next sections for monitoring
* Run 4 instance of UPerf: `bin/uperf.sh -name <NAME>`
** Make sure they find each other: the view should show 4 members
** Also make sure `run.sh` has the bind addres set to loopback, or else you'll overwhelm the wifi...
* Press `1` in one of the instances to start the test (runs for 1 minute)
* Take a look at throughput and latency
* Leave the instances running while we move on to the next section


Monitoring various scenarios
----------------------------
* In the next sections we'll be taking a look at a number of scenarios and determine which
  protocols/attributes to look at


Group membership
----------------
* Cluster falls apart frequently and merges back
* Members are excluded although they're healthy
* Protocols to look at: `FD_ALL` / `FD_SOCK` (failure detection):
----
[belasmac] /Users/bela$ probe.sh jmx=FD_ALL.num_ jmx=FD_SOCK.num_

#1 (265 bytes):
local_addr=D [ip=127.0.0.1:64647, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
FD_ALL={num_heartbeats_received=1576, num_heartbeats_sent=394, num_suspect_events=0}
FD_SOCK={num_suspect_events_generated=0, num_suspected_members=0, num_tries=3}

#2 (265 bytes):
local_addr=A [ip=127.0.0.1:56329, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
FD_ALL={num_heartbeats_received=1581, num_heartbeats_sent=396, num_suspect_events=0}
FD_SOCK={num_suspect_events_generated=0, num_suspected_members=0, num_tries=3}

#3 (265 bytes):
local_addr=B [ip=127.0.0.1:62680, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
FD_ALL={num_heartbeats_received=1581, num_heartbeats_sent=396, num_suspect_events=0}
FD_SOCK={num_suspect_events_generated=0, num_suspected_members=0, num_tries=3}

#4 (265 bytes):
local_addr=C [ip=127.0.0.1:59995, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
FD_ALL={num_heartbeats_received=1579, num_heartbeats_sent=395, num_suspect_events=0}
FD_SOCK={num_suspect_events_generated=0, num_suspected_members=0, num_tries=3}
----
* We can see that both failure detection protocols show 0 suspect events.
* `FD_ALL` does show sent and received heartbeats
* If members are suspected falsely, one of the protocols would have a higher value for the number of suspicions
* Then we'd have to focus on that protocol: enable logging, look at other attributes, invoke operations etc


Finding out which attributes and operations are available in a protocol
-----------------------------------------------------------------------
* Sometimes it is useful to know the history of views, so we need to see if `GMS` exposes anything interesting
* Look at `GMS.java` and search for `@ManagedAttribute`, `@Property` or `@ManagedOperation`:
----
cat GMS.java |grep -e "@Managed" -A 2 -e "@Property" -A 2|more
----
* We can see that there is an operation to print the previous views (output edited):
----
[belasmac] /Users/bela$ probe.sh op=GMS.printPreviousViews

#1 (322 bytes):
local_addr=A [ip=127.0.0.1:56329, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
GMS.printPreviousViews=
Wed Aug 23 10:39:00 CEST 2017: [A|0] (1) [A]
Wed Aug 23 10:39:14 CEST 2017: [A|1] (2) [A, B]
Wed Aug 23 10:39:25 CEST 2017: [A|2] (3) [A, B, C]
Wed Aug 23 10:39:33 CEST 2017: [A|3] (4) [A, B, C, D]

#2 (277 bytes):
local_addr=B [ip=127.0.0.1:62680, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
GMS.printPreviousViews=
Wed Aug 23 10:39:14 CEST 2017: [A|1] (2) [A, B]
Wed Aug 23 10:39:25 CEST 2017: [A|2] (3) [A, B, C]
Wed Aug 23 10:39:33 CEST 2017: [A|3] (4) [A, B, C, D]

#3 (229 bytes):
local_addr=C [ip=127.0.0.1:59995, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
GMS.printPreviousViews=
Wed Aug 23 10:39:25 CEST 2017: [A|2] (3) [A, B, C]
Wed Aug 23 10:39:33 CEST 2017: [A|3] (4) [A, B, C, D]

#4 (178 bytes):
local_addr=D [ip=127.0.0.1:64647, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
GMS.printPreviousViews=Wed Aug 23 10:39:33 CEST 2017: [A|3] (4) [A, B, C, D]
----
* This shows that `A` created the first view `A|0` and therefore became coordinator
* Next `B` joined: `A` installed view `A|1` consisting of `A` and `B`, and `B` installed this view as its first view
* Next `C` join, creating view `A|2` and so on
* This looks perfectly ok, but if we had high view IDs, this would point to a high membership churn rate
** This might be ok if we have many members leaving and joining frequently, but if not, it is probably a result of
   frequent false suspicions: look at which protocol does the suspicions and possibly change attributes (e.g. failure
   detection timeouts)



Exhausted thread pools
----------------------
* Oftentimes pools are too small
* The result is that messages get rejected and dropped
** If the dropped messages are unreliable, they won't get retransmitted, e.g. heartbeats -> this could lead to false
   suspicions
** If the dropped message are reliable, they will get retransmitted -> confirm this by looking at retransmission stats
* Let's look at the thread pool sizes first:
[.small]
----
[belasmac] /Users/bela$ probe.sh jmx=UDP.thread_pool.max,thread_pool_si


#1 (209 bytes):
local_addr=D [ip=127.0.0.1:64647, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
UDP={thread_pool.max_threads=20, thread_pool_size=1, thread_pool_size_active=0, thread_pool_size_largest=20}

#2 (209 bytes):
local_addr=C [ip=127.0.0.1:59995, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
UDP={thread_pool.max_threads=20, thread_pool_size=1, thread_pool_size_active=0, thread_pool_size_largest=20}

#3 (209 bytes):
local_addr=A [ip=127.0.0.1:56329, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
UDP={thread_pool.max_threads=20, thread_pool_size=1, thread_pool_size_active=0, thread_pool_size_largest=20}

#4 (209 bytes):
local_addr=B [ip=127.0.0.1:62680, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
UDP={thread_pool.max_threads=20, thread_pool_size=1, thread_pool_size_active=0, thread_pool_size_largest=20}
----
* First, we can see that the max size is 20 (`thread_pool.max_threads`)
* However, the largest thread pool size is also 20 (it cannot get higher than max-size)
** This could mean that the thread pool was exhausted
** Let's check if we got rejected messages as a result:
----
[belasmac] /Users/bela$ probe.sh jmx=UDP.num_re

#1 (128 bytes):
local_addr=D [ip=127.0.0.1:64647, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
UDP={num_rejected_msgs=643}

#2 (128 bytes):
local_addr=B [ip=127.0.0.1:62680, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
UDP={num_rejected_msgs=849}

#3 (128 bytes):
local_addr=A [ip=127.0.0.1:56329, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
UDP={num_rejected_msgs=590}

#4 (128 bytes):
local_addr=C [ip=127.0.0.1:59995, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
UDP={num_rejected_msgs=283}
----
* Yes, we did get messages rejected! This means that the thread pool was too small and its max size needs to
  be increased
* We can confirm that we did indeed get retransmissions (we're checking both unicast and multicast retransmissions):
----
[belasmac] /Users/bela$ probe.sh jmx=NAKACK2.xmit_r jmx=UNICAST3.xmit_r

#1 (266 bytes):
local_addr=C [ip=127.0.0.1:59995, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
NAKACK2={xmit_reqs_received=0, xmit_reqs_sent=0, xmit_rsps_received=0, xmit_rsps_sent=0}
UNICAST3={xmit_reqs_received=1492, xmit_reqs_sent=688, xmit_rsps_sent=1490}

#2 (267 bytes):
local_addr=B [ip=127.0.0.1:62680, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
NAKACK2={xmit_reqs_received=0, xmit_reqs_sent=0, xmit_rsps_received=0, xmit_rsps_sent=0}
UNICAST3={xmit_reqs_received=1091, xmit_reqs_sent=1692, xmit_rsps_sent=1091}

#3 (267 bytes):
local_addr=A [ip=127.0.0.1:56329, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
NAKACK2={xmit_reqs_received=0, xmit_reqs_sent=0, xmit_rsps_received=0, xmit_rsps_sent=0}
UNICAST3={xmit_reqs_received=1314, xmit_reqs_sent=1179, xmit_rsps_sent=1314}

#4 (267 bytes):
local_addr=D [ip=127.0.0.1:64647, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
NAKACK2={xmit_reqs_received=0, xmit_reqs_sent=0, xmit_rsps_received=0, xmit_rsps_sent=0}
UNICAST3={xmit_reqs_received=1022, xmit_reqs_sent=1360, xmit_rsps_sent=1014}
----
* We can see that there were unicast retransmissions -> this confirms that our thread pool was too small


How to find the right size
--------------------------
* Run the application
* Change the thread pool at runtime:
----
probe.sh op=UDP.setThreadPoolMaxThreads[100]
----
* Look at the largest thread pool size again:
----
[belasmac] /Users/bela$ probe.sh jmx=UDP.thread_pool.max,thread_pool_si

#1 (211 bytes):
local_addr=B [ip=127.0.0.1:62680, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
UDP={thread_pool.max_threads=100, thread_pool_size=23, thread_pool_size_active=0, thread_pool_size_largest=37}

#2 (211 bytes):
local_addr=C [ip=127.0.0.1:59995, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
UDP={thread_pool.max_threads=100, thread_pool_size=22, thread_pool_size_active=0, thread_pool_size_largest=50}

#3 (211 bytes):
local_addr=A [ip=127.0.0.1:56329, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
UDP={thread_pool.max_threads=100, thread_pool_size=24, thread_pool_size_active=0, thread_pool_size_largest=50}

#4 (211 bytes):
local_addr=D [ip=127.0.0.1:64647, version=4.0.6-SNAPSHOT (Schiener Berg), cluster=uperf, 4 mbr(s)]
UDP={thread_pool.max_threads=100, thread_pool_size=28, thread_pool_size_active=0, thread_pool_size_largest=40}
----
* The max-size is indeed 100 and this seemed to help as the largest sizes are 50 or less now
* The suggestion is to have relatively high max sizes to cover peaks: after some idle time, threads are going to be
  removed from the pool again.

NOTE: Because `UPerf` uses `OOB` messages, the pool sizes are relatively high. Had we used regular messages, those
      sizes would have been smaller



























